<!DOCTYPE html>

<html lang="en">
<head>
<script data-blockingmode="auto" data-cbid="272e4128-6678-430d-aa67-2f4d13d1d783" id="Cookiebot" src="https://consent.cookiebot.com/uc.js" type="text/javascript"></script>
<title>Robin Beer - How to setup dbt DataOps with GitLab CI/CD for a Snowflake cloud data warehouse</title>
<link href="https://www.robin-beer.de\drafts/how-to-setup-dbt-dataops-with-gitlab-cicd-for-a-snowflake-cloud-data-warehouse.html" rel="canonical"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": "BreadcrumbList", "itemListElement": [{"@type": "ListItem", "position": 1, "name": "Robin Beer", "item": "https://www.robin-beer.de"}, {"@type": "ListItem", "position": 2, "name": "Drafts", "item": "https://www.robin-beer.de\\drafts"}, {"@type": "ListItem", "position": 3, "name": "How to setup dbt dataops with gitlab cicd for a snowflake cloud data warehouse", "item": "https://www.robin-beer.de\\drafts/how-to-setup-dbt-dataops-with-gitlab-cicd-for-a-snowflake-cloud-data-warehouse.html"}]}</script><script type="application/ld+json">{"@context": "https://schema.org", "@type": "Article", "author": {"@type": "Person", "name": "Robin Beer"}, "publisher": {"@type": "Organization", "name": "Robin Beer"}, "headline": "How to setup dbt DataOps with GitLab CI/CD for a Snowflake cloud data warehouse", "about": "Tools", "datePublished": "2020-06-05 00:00"}</script></head>
<body>
<div class="container">
<section class="body" id="content">
<header>
<h2 class="entry-title">
<a href="https://www.robin-beer.de/drafts/how-to-setup-dbt-dataops-with-gitlab-cicd-for-a-snowflake-cloud-data-warehouse.html" rel="bookmark" title="Permalink to How to setup dbt DataOps with GitLab CI/CD for a Snowflake cloud data warehouse">How to setup dbt DataOps with GitLab CI/CD for a Snowflake cloud data warehouse</a></h2>
</header>
<footer class="post-info">
<time class="published" datetime="2020-06-05T00:00:00+02:00">
      Fri 05 June 2020
    </time>
<address class="vcard author">
      By           <a class="url fn" href="https://www.robin-beer.de/author/robin-beer.html">Robin Beer</a>
</address>
<div class="category">
        Category: <a href="https://www.robin-beer.de/category/tools.html">Tools</a>
</div>
<div class="tags">
        Tags:
            <a href="https://www.robin-beer.de/tag/howto.html">HowTo</a>
<a href="https://www.robin-beer.de/tag/backend.html">backend</a>
<a href="https://www.robin-beer.de/tag/dataops.html">dataops</a>
<a href="https://www.robin-beer.de/tag/gitlab.html">GitLab</a>
</div>
</footer><!-- /.post-info -->
<div class="entry-content">
<p>If you are working with databases, you probably also work with SQL.
Although SQL is simple to learn, you might already have asked yourself whether it wasn't possible to write object-oriented SQL... :thinking:</p>
<p>There is: using dbt! :) </p>
<p>The data build tool (dbt) is "the T in ELT" - hence the "transform" in Extract Load Transform. If you are new to cloud data warehouses, ELT etc. you might want to read the article <a href="https://community.snowflake.com/s/article/Using-DBT-to-Execute-ELT-Pipelines-in-Snowflake">USING DBT TO EXECUTE ELT PIPELINES IN SNOWFLAKE</a>.</p>
<p>However, to get up and running within 15 min with a simple dbt example and GitLab CI configuration, I invite you to read this article.</p>
<!-- https://www.youtube.com/watch?v=-XBIIY2pFpc&feature=youtu.be&t=1305 -->
<h2>Local installation</h2>
<p>First of all, create a new virtual environment of your choice to install dbt, for example using conda:</p>
<div class="highlight"><pre><span></span><code>conda create -n dbt_test <span class="nv">python</span><span class="o">=</span><span class="m">3</span>.8
</code></pre></div>
<p>Then, install dbt using pip:</p>
<div class="highlight"><pre><span></span><code>pip install dbt
</code></pre></div>
<p>When completed, you can create an example project:</p>
<div class="highlight"><pre><span></span><code>dbt init dbt_test
</code></pre></div>
<h2>BigQuery or snowflake config</h2>
<p>If you do not yet have a cloud data warehouse I invite you to follow the <a href="https://docs.getdbt.com/tutorial/setting-up">official dbt tutorial to get started</a> in which you will setup BigQuery. If you already have a cloud data warehouse, check out the <a href="https://docs.getdbt.com/docs/supported-databases">supported databases</a>.</p>
<p>Check out dbt's documentation on <a href="https://docs.getdbt.com/docs/supported-databases/profile-snowflake/">how to configure dbt profiles for snowflake</a>.</p>
<p>It basically comes down to creating a <code>~/.dbt/profiles.yml</code> with the following content:</p>
<div class="highlight"><pre><span></span><code><span class="n">my</span><span class="o">-</span><span class="n">snowflake</span><span class="o">-</span><span class="nl">db</span><span class="p">:</span>
  <span class="nl">target</span><span class="p">:</span> <span class="n">dev</span>
  <span class="nl">outputs</span><span class="p">:</span>
    <span class="nl">dev</span><span class="p">:</span>
      <span class="nl">type</span><span class="p">:</span> <span class="n">snowflake</span>
      <span class="nl">account</span><span class="p">:</span> <span class="p">[</span><span class="n">account</span> <span class="kt">id</span><span class="p">]</span>

      <span class="cp"># User/password auth</span>
      <span class="nl">user</span><span class="p">:</span> <span class="p">[</span><span class="n">username</span><span class="p">]</span>
      <span class="nl">password</span><span class="p">:</span> <span class="p">[</span><span class="n">password</span><span class="p">]</span>

      <span class="nl">role</span><span class="p">:</span> <span class="p">[</span><span class="n">user</span> <span class="n">role</span><span class="p">]</span>
      <span class="nl">database</span><span class="p">:</span> <span class="p">[</span><span class="n">database</span> <span class="n">name</span><span class="p">]</span>
      <span class="nl">warehouse</span><span class="p">:</span> <span class="p">[</span><span class="n">warehouse</span> <span class="n">name</span><span class="p">]</span>
      <span class="nl">schema</span><span class="p">:</span> <span class="p">[</span><span class="n">dbt</span> <span class="n">schema</span><span class="p">]</span>
      <span class="nl">threads</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span> <span class="n">or</span> <span class="n">more</span><span class="p">]</span>
      <span class="nl">client_session_keep_alive</span><span class="p">:</span> <span class="n">False</span>
</code></pre></div>
<p>This profile must be chosen in the <code>dbt_project.yml</code>:</p>
<div class="highlight"><pre><span></span><code><span class="x"># Name your project! Project names should contain only lowercase characters</span>
<span class="x"># and underscores. A good package name should reflect your organization's</span>
<span class="x"># name or the intended use of these models</span>
<span class="x">name: 'snowflake_dbt_test'</span>
<span class="x">version: '1.0.0'</span>

<span class="x"># This setting configures which "profile" dbt uses for this project.</span>
<span class="x">profile: 'my-snowflake-db'</span>

<span class="x"># These configurations specify where dbt should look for different types of files.</span>
<span class="x"># The `source-paths` config, for example, states that models in this project can be</span>
<span class="x"># found in the "models/" directory. You probably won't need to change these!</span>
<span class="x">source-paths: ["models"]</span>
<span class="x">analysis-paths: ["analysis"]</span>
<span class="x">test-paths: ["tests"]</span>
<span class="x">data-paths: ["data"]</span>
<span class="x">macro-paths: ["macros"]</span>
<span class="x">snapshot-paths: ["snapshots"]</span>

<span class="x">target-path: "target"  # directory which will store compiled SQL files</span>
<span class="x">clean-targets:         # directories to be removed by `dbt clean`</span>
<span class="x">    - "target"</span>
<span class="x">    - "dbt_modules"</span>


<span class="x"># Configuring models</span>
<span class="x"># Full documentation: https://docs.getdbt.com/docs/configuring-models</span>

<span class="x"># In this example config, we tell dbt to build all models in the example/ directory</span>
<span class="x"># as tables. These settings can be overridden in the individual model files</span>
<span class="x"># using the `</span><span class="cp">{{</span> <span class="nv">config</span><span class="o">(</span><span class="err">...</span><span class="o">)</span> <span class="cp">}}</span><span class="x">` macro.</span>
<span class="x">models:</span>
<span class="x">  snowflake_dbt_test:</span>
<span class="x">      # Applies to all files under models/example/</span>
<span class="x">      example:</span>
<span class="x">          materialized: view</span>
</code></pre></div>
<h2>Write your first dbt models</h2>
<p>Now that dbt is installed and you have configured it to use your cloud data warehouse credentials, let's build our first model.</p>
<p>Open the package <code>dbt_test</code> that you have previously created using <code>dbt init</code>. </p>
<p>Under <code>models/example</code> delete the existing sql files and instead create a <code>simple.sql</code> with a content similar to the following:</p>
<div class="highlight"><pre><span></span><code><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">TABLE_IN_DATABASE</span>
</code></pre></div>
<p>This query would be executed on the database that you configured in <code>~/.dbt/profiles.yml</code>, thus creating a view called <code>snowflake_dbt_test</code> in the database.</p>
<h2>Execute the dbt models locally</h2>
<p>How to execute dbt and create this view in the database?</p>
<p>Well, activate your virtual environment (e.g. using <code>conda activate dbt-test</code>) and run the following command in your dbt package folder (<code>.../dbt_test/</code>):</p>
<div class="highlight"><pre><span></span><code>dbt run
</code></pre></div>
<p>The command should run through without errors and you can check the given schema of the database for the newly created view <code>snowflake_dbt_test</code>.</p>
<h2>GitLab CI/CD pipeline</h2>
<p>You might want your dbt code to be run automatically in a CI/CD pipeline as part of DataOps.</p>
<p>First, create a repository on your GitLab instance and push your local code to it. Then, add your snowflake environment variables under <code>Settings -&gt; CI/CD -&gt; Variables (Expand)</code> by clicking on <code>Add Variable</code>:</p>
<p><img alt="GitLab CI/CD Snowflake environment variables" src="2020-06-06-00-32-07.png"/></p>
<p>To load these environment variables into the pipeline, create the file <code>profile/profiles.yml</code> with the following content (inspired by <a href="https://gitlab.com/gitlab-data/analytics/-/blob/master/transform/snowflake-dbt/profile/profiles.yml">GitLab's profiles.yml</a>):</p>
<div class="highlight"><pre><span></span><code><span class="n">my</span><span class="o">-</span><span class="n">snowflake</span><span class="o">-</span><span class="n">db</span><span class="p">:</span>
  <span class="n">target</span><span class="p">:</span> <span class="n">dev</span>
  <span class="n">outputs</span><span class="p">:</span>
    <span class="n">dev</span><span class="p">:</span>
      <span class="n">type</span><span class="p">:</span> <span class="n">snowflake</span>
      <span class="n">threads</span><span class="p">:</span> <span class="mi">1</span>
      <span class="n">account</span><span class="p">:</span> <span class="s2">"{{ env_var('SNOWFLAKE_ACCOUNT') }}"</span>
      <span class="n">user</span><span class="p">:</span> <span class="s2">"{{ env_var('SNOWFLAKE_USER') }}"</span>
      <span class="n">password</span><span class="p">:</span> <span class="s2">"{{ env_var('SNOWFLAKE_PASSWORD') }}"</span>
      <span class="n">database</span><span class="p">:</span> <span class="s2">"{{ env_var('SNOWFLAKE_TRANSFORM_DATABASE') }}"</span>
      <span class="n">role</span><span class="p">:</span> <span class="s2">"{{ env_var('SNOWFLAKE_TRANSFORM_ROLE') }}"</span>
      <span class="n">warehouse</span><span class="p">:</span> <span class="s2">"{{ env_var('SNOWFLAKE_TRANSFORM_WAREHOUSE') }}"</span>
      <span class="n">schema</span><span class="p">:</span> <span class="s2">"{{ env_var('SNOWFLAKE_TRANSFORM_SCHEMA') }}"</span>
      <span class="n">client_session_keep_alive</span><span class="p">:</span> <span class="n">False</span>
</code></pre></div>
<p>Now, add the following <code>.gitlab-ci.yml</code> within your GitLab repository:</p>
<div class="highlight"><pre><span></span><code>image: python:latest

variables:
  PIP_CACHE_DIR: <span class="s2">"</span><span class="nv">$CI_PROJECT_DIR</span><span class="s2">/.cache/pip"</span>

cache:
  paths:
    - .cache/pip
    - venv/

before_script:
  - python -V  <span class="c1"># Print out python version for debugging</span>
  - pip install virtualenv
  - virtualenv venv
  - <span class="nb">source</span> venv/bin/activate
  - pip install dbt
  - <span class="nb">export</span> <span class="nv">CI_PROFILE_TARGET</span><span class="o">=</span><span class="s2">"--profiles-dir profile --target dev"</span>
  - <span class="nb">echo</span> <span class="nv">$CI_PROFILE_TARGET</span>

run:
  script:
     dbt run <span class="nv">$CI_PROFILE_TARGET</span> 
</code></pre></div>
<p>When committing this change, the CI/CD pipeline should be automatically triggered. If all environment variables are set correctly and the dbt models worked locally, the pipeline should also succeed. Congratulations!</p>
<h2>Conclusion</h2>
<p><a href="https://www.getdbt.com">dbt</a> stands for "data build tool" and can be described as "the T in ELT".
It's a tool that is used by a growing community to write DRY SQL, create dbt packages and add DataOps to it.</p>
<p>With this article, you have locally installed it, built your own simple dbt model and connected and tested it on snowflake (or BigQuery).</p>
<p>Finally, you have set up a CI/CD pipeline on GitLab to complete the DataOps setup.</p>
<p>Now, if dbt rose your interest, join the <a href="https://community.getdbt.com">dbt slack channel</a>, the <a href="https://discourse.getdbt.com">dbt discours</a> or check out the <a href="https://about.gitlab.com/handbook/business-ops/data-team/">information on how the GitLab Data Team leverages dbt</a> for more detailed insights in how dbt can be used.</p>
<p>See you in the community!</p>
<p>Robin</p>
</div><!-- /.entry-content -->
</section>
</div>
</body>
</html>